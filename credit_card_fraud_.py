# -*- coding: utf-8 -*-
"""Credit Card Fraud .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17E1KN6SvBAQC2OLXOPn_MpQCRJ_McXBY
"""

!mkdir ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d mlg-ulb/creditcardfraud
!unzip creditcardfraud.zip

import pandas as pd

df=pd.read_csv('creditcard.csv')

df

df['Class'].value_counts() # 1 indicate fraud classes

df.hist(bins=30,figsize=(30,30))

df.describe()

from sklearn.preprocessing import RobustScaler,MinMaxScaler
new_df=df.copy()
new_df['Amount']=RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1,1))

new_df['Amount'].hist()

new_df['Time']=MinMaxScaler().fit_transform(new_df['Time'].to_numpy().reshape(-1,1))

new_df

new_df=new_df.sample(frac=1,random_state=1)

train,test,val=new_df[:240000],new_df[240000:262000],new_df[262000:]

train['Class'].value_counts()

train_np,test_np,val_np=train.to_numpy(),test.to_numpy(),val.to_numpy()
train.shape,test.shape,val.shape

X_train,y_train=train_np[:,:-1],train_np[:,-1]
X_test,y_test=test_np[:,:-1],test_np[:,-1]
X_val,y_val=val_np[:,:-1],val_np[:,-1]

X_train.shape,y_train.shape,X_test.shape,y_test.shape,X_val.shape,y_val.shape

from sklearn.linear_model import LogisticRegression
logistic_model=LogisticRegression()
logistic_model.fit(X_train,y_train)
logistic_model.score(X_train,y_train)

y_pred=logistic_model.predict(X_val)
from sklearn.metrics import classification_report
print(classification_report(y_val, y_pred, target_names=['Not Fraud', 'Fraud']))



shallow_nm=Sequential()
shallow_nm.add(InputLayer((X_train.shape[1],)))
shallow_nm.add(Dense(2,activation='relu'))
shallow_nm.add(BatchNormalization())
shallow_nm.add(Dense(1,activation='sigmoid'))
checkpoint=ModelCheckpoint('shallow_nm.keras', save_best_only=True)
shallow_nm.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])

shallow_nm.fit(X_train,y_train,validation_data=(X_val,y_val),epochs=5,callbacks=checkpoint)
print(classification_report(y_val,shallow_nm.predict(X_val),target_names=['Not Fraud','Fraud']))

def neural_net_predictions(model,x):
  return (model.predict(x).flatten()>0.5).astype(int)

neural_net_predictions(shallow_nm,X_val)

print(classification_report(y_val,neural_net_predictions(shallow_nm,X_val),target_names=['Not Fraud','Fraud']))

from sklearn.metrics import confusion_matrix

y_pred=shallow_nm.predict(X_train)>0.5
cm=confusion_matrix(y_train,y_pred)
print(cm)

from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier(max_depth=2,n_jobs=-1)
rf.fit(X_train,y_train)
print(classification_report(y_val,rf.predict(X_val),target_names=['Not Fraud','Fraud']))

from sklearn.ensemble import GradientBoostingClassifier
gbc=GradientBoostingClassifier(n_estimators=50,learning_rate=0.1,max_depth=2,random_state=0)
gbc.fit(X_train,y_train)
print(classification_report(y_val,gbc.predict(X_val),target_names=['Not Fraud','Fraud']))

from sklearn.svm import LinearSVC

svc=LinearSVC(class_weight='balanced')
svc.fit(X_train,y_train)
print(classification_report(y_val,svc.predict(X_val),target_names=['Not Fraud','Fraud']))

not_frauds=new_df.query('Class==0')
frauds=new_df.query('Class==1')
not_frauds['Class'].value_counts(), frauds['Class'].value_counts(

)

balanced_df=pd.concat([frauds,not_frauds.sample(len(frauds),random_state=1)])

balanced_df['Class'].value_counts()

balanced_df=balanced_df.sample(frac=1,random_state=1)

balanced_df

balanced_df_np=balanced_df.to_numpy()
X_train_b,y_train_b=balanced_df_np[:700,:-1],balanced_df_np[:700,-1].astype(int)
X_test_b,y_test_b=balanced_df_np[700:842,:-1],balanced_df_np[700:842,-1].astype(int)
X_val_b,y_val_b=balanced_df_np[842:,:-1],balanced_df_np[842:,-1].astype(int)

X_train_b.shape,y_train_b.shape,X_test_b.shape,y_test_b.shape,X_val_b.shape,y_val_b.shape

pd.Series(y_train_b).value_counts(),pd.Series(y_val_b).value_counts(),pd.Series(y_test_b).value_counts()

logistic_model_b=LogisticRegression()
 logistic_model_b.fit(X_train_b,y_train_b)
 logistic_model_b.score(X_train_b,y_train_b)

print(classification_report(y_val_b,logistic_model_b.predict(X_val_b),target_names=['Not Fraud','Fraud']))

shallow_nn_b=Sequential()
shallow_nn_b.add(InputLayer((X_train_b.shape[1],)))
shallow_nn_b.add(Dense(2,activation='relu'))
shallow_nn_b.add(BatchNormalization())
shallow_nn_b.add(Dense(1,activation='sigmoid'))
checkpoint=ModelCheckpoint('shallow_nn_b.keras',save_best_only=True)
shallow_nn_b.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])
shallow_nn_b.fit(X_train_b,y_train_b,validation_data=(X_val_b,y_val_b),epochs=40,callbacks=checkpoint)

shallow_nn_b.fit(X_train_b,y_train_b,validation_data=(X_val_b,y_val_b),epochs=40,callbacks=checkpoint)

print(classification_report(y_val_b,neural_net_predictions(shallow_nn_b,X_val_b),target_names=['Not Fraud','Fraud']))

rf_b=RandomForestClassifier()
rf_b.fit(X_train_b,y_train_b)
print(classification_report(y_val_b,rf_b.predict(X_val_b),target_names=['Not Fraud','Fraud']))

gbc_b=GradientBoostingClassifier(n_estimators=50,learning_rate=0.1,max_depth=2,random_state=0)
gbc_b.fit(X_train_b,y_train_b)
print(classification_report(y_val_b,gbc_b.predict(X_val_b),target_names=['Not Fraud','Fraud']))

print(classification_report(y_test,neural_net_predictions(shallow_nm,X_test),target_names=['Not Fraud','Fraud']))

# Minimal necessary-metrics evaluator
import numpy as np
from sklearn.metrics import (accuracy_score, balanced_accuracy_score, precision_score,
                             recall_score, f1_score, confusion_matrix, matthews_corrcoef,
                             roc_auc_score, average_precision_score, log_loss, brier_score_loss)

def eval_minimal(model, X, y):
    y_true = np.asarray(y).astype(int)
    # labels (try wrapper, then model.predict)
    try:
        y_pred = np.asarray(neural_net_predictions(model, X)).astype(int)
    except Exception:
        y_pred = np.asarray(model.predict(X))
        if y_pred.ndim > 1 and y_pred.shape[1] > 1:
            y_pred = np.argmax(y_pred, axis=1)
        y_pred = y_pred.astype(int)

    # probs (if available)
    y_proba = None
    try:
        if hasattr(model, "predict_proba"):
            p = np.asarray(model.predict_proba(X))
            y_proba = p[:,1] if p.ndim==2 and p.shape[1]>1 else p.ravel()
        else:
            p = np.asarray(model.predict(X)); y_proba = p.ravel()
    except Exception:
        y_proba = None

    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    res = {
        "accuracy": accuracy_score(y_true, y_pred),
        "balanced_accuracy": balanced_accuracy_score(y_true, y_pred),
        "precision_pos": precision_score(y_true, y_pred, pos_label=1, zero_division=0),
        "recall_pos": recall_score(y_true, y_pred, pos_label=1, zero_division=0),
        "f1_pos": f1_score(y_true, y_pred, pos_label=1, zero_division=0),
        "confusion": {"tn":int(tn),"fp":int(fp),"fn":int(fn),"tp":int(tp)},
        "mcc": matthews_corrcoef(y_true, y_pred)
    }

    if y_proba is not None:
        try: res["roc_auc"] = roc_auc_score(y_true, y_proba)
        except: res["roc_auc"] = None
        try: res["pr_auc"] = average_precision_score(y_true, y_proba)
        except: res["pr_auc"] = None
        try: res["log_loss"] = log_loss(y_true, y_proba)
        except: res["log_loss"] = None
        try: res["brier"] = brier_score_loss(y_true, y_proba)
        except: res["brier"] = None
    else:
        res.update({"roc_auc":None,"pr_auc":None,"log_loss":None,"brier":None})

    # concise print
    print(f"Acc: {res['accuracy']:.4f} | BalAcc: {res['balanced_accuracy']:.4f}")
    print(f"P: {res['precision_pos']:.4f} | R: {res['recall_pos']:.4f} | F1: {res['f1_pos']:.4f} | MCC: {res['mcc']:.4f}")
    print("CM:", res["confusion"])
    if res["roc_auc"] is not None:
        print(f"ROC-AUC: {res['roc_auc']:.4f} | PR-AUC: {res['pr_auc']:.4f} | LogLoss: {res['log_loss']:.4f} | Brier: {res['brier']:.4f}")
    else:
        print("Probability metrics skipped (no probabilities available).")
    return res

metrics = eval_minimal(shallow_nm, X_test, y_test)

